{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2. NER with LSTM + CRF\n",
    "Another experiement I ran for the NER task with RNN based models is a bidirectional LSTM + CRF. I used a Bidirectional LSTM unit to learn the word embeddings and input to output mapping, and passed the output word vectors as input sequences to the CRF module to incorporate the label transition probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# sklearn imports\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict\n",
    "\n",
    "# pytorch imports \n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# set a random seed\n",
    "torch.manual_seed(10);\n",
    "\n",
    "# model saving and inspection\n",
    "import joblib\n",
    "import eli5\n",
    "from datetime import datetime\n",
    "\n",
    "import pdb # debugging\n",
    "\n",
    "# auto-reloads\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.20.0\n",
      "pytorch version: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "# make sure we are using pytorch > 0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '..', '', '/home/hayley/miniconda3/envs/fastai/lib/python36.zip', '/home/hayley/miniconda3/envs/fastai/lib/python3.6', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/lib-dynload', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages/defusedxml-0.5.0-py3.6.egg', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions', '/home/hayley/.ipython']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '..', '', '/home/hayley/miniconda3/envs/fastai/lib/python36.zip', '/home/hayley/miniconda3/envs/fastai/lib/python3.6', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/lib-dynload', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages/defusedxml-0.5.0-py3.6.egg', '/home/hayley/miniconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions', '/home/hayley/.ipython']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hayley/Workspace/Class/IE/HW1/notebooks'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utils import data_converter, conlleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_iob = data_converter.read_conll('../data/eng.train')[1:] #ignore header\n",
    "train_data_bio = data_converter.read_conll('../data/train.bio')[1:] #ignore header\n",
    "dev_data_bio = data_converter.read_conll('../data/testa.bio')[1:]\n",
    "test_data = data_converter.read_conll('../data/eng.testb')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data_bio.copy()\n",
    "all_data.extend(dev_data_bio)\n",
    "all_data.extend(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes\n",
      " train, dev, test, all\n",
      "[14985, 3464, 3683, 22132]\n"
     ]
    }
   ],
   "source": [
    "datasets = [train_data_bio, dev_data_bio, test_data, all_data]\n",
    "print(\"Dataset sizes\")\n",
    "print(\" train, dev, test, all\")\n",
    "print(list(map(lambda data: len(data), datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = joblib.load('../data/train_sentences.sav')\n",
    "train_labels = joblib.load('../data/train_labels.sav')\n",
    "\n",
    "dev_sentences = joblib.load('../data/testa_sentences.sav')\n",
    "dev_labels = joblib.load('../data/testa_labels.sav')\n",
    "\n",
    "test_sentences = joblib.load('../data/testb_sentences.sav')\n",
    "\n",
    "# indice mappers\n",
    "word2idx = joblib.load('../data/word2idx.sav')\n",
    "tag2idx = joblib.load('../data/tag2idx.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences:  10490 10490\n",
      "dev sentences:  3464 3464\n",
      "test sentences:  3683\n",
      "vocab size:  15002\n",
      "number of tags:  11\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics on the datasets and lookup tables\n",
    "print('train sentences: ', len(train_sentences), len(train_labels))\n",
    "print('dev sentences: ', len(dev_sentences), len(dev_labels))\n",
    "print('test sentences: ', len(test_sentences))\n",
    "print('vocab size: ', len(word2idx))\n",
    "print('number of tags: ', len(tag2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the CRF models, we don't need to hand-engineer the features for our word representation. Instead, we use the embedding matrix and learn the parameters for a vector representation of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define START AND STOP TAGS\n",
    "START_TAG = '<START>'\n",
    "STOP_TAG = '<STOP>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: EU, idx: 1045\n",
      "inv_w: EU\n",
      "w: German, idx: 238\n",
      "inv_w: German\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "idx2word = {i:w for (w,i) in word2idx.items()}\n",
    "some_words = ['EU', 'German']\n",
    "for w in some_words:\n",
    "    idx = word2idx[w]\n",
    "    print(f'w: {w}, idx: {idx}')\n",
    "    inv_w = idx2word[idx]\n",
    "    print(f'inv_w: {inv_w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Let's define some helper functions for the Viterbi algorithm and the input sentence processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerically stable log-sum computation for Viterbi forward\n",
    "def log_sum_exp(vec):\n",
    "    vec = vec.view(1,-1)\n",
    "    max_val, _ = torch.max(vec, 1)\n",
    "    return max_val + torch.log(torch.sum(torch.exp(vec - max_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test on log_sum_exp function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([[1000000., 1000000., 1000000., 1000000.]])\n",
      "logsumexp: tensor([1000001.3750])\n",
      "\n",
      "t: tensor([[1.0000e-10, 1.0000e-10, 1.0000e-10, 1.0000e-10]])\n",
      "logsumexp: tensor([1.3863])\n"
     ]
    }
   ],
   "source": [
    "def test_logsumexp():\n",
    "    t = torch.rand(2,2).view(1,-1).fill_(1e6)\n",
    "    print(f\"t: {t}\")\n",
    "    print(f\"logsumexp: {log_sum_exp(t)}\")\n",
    "    print(f\"\\nt: {t.fill_(1e-10)}\")\n",
    "    print(f\"logsumexp: {log_sum_exp(t)}\")\n",
    "test_logsumexp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert words and tags to corresponding indices\n",
    "def prepare_sentence(sentence, word2idx):\n",
    "    \"\"\"\n",
    "    Returns a tensor of word indices given a list of words\n",
    "    Args:\n",
    "    - sentence (list): a list of word_infos. Each word_info is a tuple of (word, ..., label)\n",
    "    - word2idx (dict): a  dictionary mapping each word in the vocab\n",
    "                        to a unique index\n",
    "    Returns:\n",
    "    - indices (torch.LongTensor): a tensor of word indices\n",
    "    - tags: (torch.LongTensor): a tensor of tag indices\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    tags = []\n",
    "    for word_info in sentence:\n",
    "        w,*_,t = word_info\n",
    "        indices.append(word2idx[w])\n",
    "        tags.append(tag2idx[t])\n",
    "\n",
    "#     return torch.tensor(indices, dtype=torch.long), torch.tensor(tags, dtype=torch.long)\n",
    "    return indices, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_indices: \n",
      "[1045, 10620, 238, 824, 5, 3808, 229, 8246, 1]\n",
      "tag_indices: \n",
      "[0, 1, 2, 1, 1, 1, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def test_prepare_sentence():\n",
    "    test_sent = train_data_bio[0]\n",
    "    word_indices, tag_indices = prepare_sentence(test_sent, word2idx)\n",
    "    print(f\"word_indices: \\n{word_indices}\")\n",
    "    print(f\"tag_indices: \\n{tag_indices}\")\n",
    "test_prepare_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BiLSTM CRF model\n",
    "Now, let's define our main model using Bidirectional LSTM for word->feature extraction \n",
    "and to learn the output probability over the tag space using CRF based model.\n",
    "\n",
    "The viterbi forward and backtracing were mostly taken from [this tutorial](https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BILSTM_CRF(nn.Module):\n",
    "    def __init__(self, dim_embedding, dim_hidden, vocab_size, tag2idx,\n",
    "                 n_lstm_layers=1):\n",
    "        super(BILSTM_CRF, self).__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag2idx = tag2idx\n",
    "        self.output_size = len(tag2idx) #n_tags\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, dim_embedding)\n",
    "        self.lstm = nn.LSTM(dim_embedding, dim_hidden//2,\n",
    "                            num_layers=n_lstm_layers, bidirectional=True)\n",
    "        \n",
    "        # output of biLSTM to tag\n",
    "        self.hidden2tag = nn.Linear(self.dim_hidden, self.output_size)\n",
    "        \n",
    "        # Transition matrix for CRF\n",
    "        ## T(i,j) = log_prob(tag_j -> tag_i). Note **from** j **to** i\n",
    "        self.transitions = nn.Parameter(torch.randn(self.output_size, self.output_size))\n",
    "        ## Never transit tag_i -> START_TAG and END_TAG -> tag_i\n",
    "        self.transitions.data[tag2idx[START_TAG], :] = -1e6\n",
    "        self.transitions.data[:, tag2idx[STOP_TAG],] = -1e6\n",
    "        \n",
    "        # Initial hidden layers\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return [torch.randn(2,1,self.dim_hidden//2), \n",
    "                torch.randn(2,1,self.dim_hidden//2)]\n",
    "    def _viterbi_forward(self, feats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - feats (tensor): output feature vector from LSTM layer\n",
    "        \"\"\"\n",
    "        # Forward pass to compute the partition function\n",
    "        init_alphas = torch.full((1, self.output_size), -1e-6)\n",
    "        \n",
    "        # Fill in the entries for START_TAG\n",
    "        init_alphas[0][self.tag2idx[START_TAG]] = 0.0\n",
    "        \n",
    "        # For automatic backprop\n",
    "        forward_var = init_alphas\n",
    "        \n",
    "        # Iterate through the sequence\n",
    "        for feat in feats:\n",
    "            alphas = []\n",
    "            for tag in range(self.output_size):\n",
    "                emit_score = torch.full((1,self.output_size), feat[tag].item())\n",
    "                \n",
    "                # jth entry of trans_score is the score of transitioning from j\n",
    "                # to tag\n",
    "                trans_score = self.transitions[tag].view(1,-1)\n",
    "                \n",
    "                tag_var = forward_var + emit_score + trans_score\n",
    "                alphas.append(log_sum_exp(tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas).view(1,-1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag2idx[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "    \n",
    "    def _get_lstm_features(self, sentence):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - sentence (torch.LongTensor): a 1D LongTensor of word indices\n",
    "        \"\"\"\n",
    "        self.hidden = self.init_hidden()\n",
    "        embedding = self.embedding(sentence).view(len(sentence), 1, -1)\n",
    "        \n",
    "        # Forward through LSTM\n",
    "        lstm_out, self.hidden = self.lstm(embedding, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.dim_hidden)\n",
    "        \n",
    "        # Forward the feature vector from LSTM to output activation\n",
    "        # through another linear layer\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Returns the score of the input tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        \n",
    "        # Prepend the START_TAG\n",
    "        tags = torch.cat([torch.tensor([self.tag2idx[START_TAG]], dtype=torch.long),\n",
    "                          tags])\n",
    "        \n",
    "        for i, feat in enumerate(feats):\n",
    "            score += self.transitions[tags[i+1], tags[i]] + feat[tags[i+1]]\n",
    "      \n",
    "        # Lastly, add the transition score to the STOP_TAG\n",
    "        score += self.transitions[self.tag2idx[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "    \n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "        \n",
    "        # Initialize the viterbi vars in log domain\n",
    "        init_vvars = torch.full( (1, self.output_size), -1e6 )\n",
    "        init_vvars[0][self.tag2idx[START_TAG]] = 0 # initial starting point\n",
    "        \n",
    "        # Forward viterbi algorithm\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            \n",
    "            bptrs = [] # backpointers for this time step\n",
    "            vvars = [] # viberbi vars for this time step\n",
    "            for tag in range(self.output_size):\n",
    "                tag_var = forward_var + self.transitions[tag]\n",
    "                _, best_tid = torch.max(tag_var,1)\n",
    "                best_tid = best_tid.item()\n",
    "                bptrs.append(best_tid)\n",
    "                vvars.append(tag_var[0][best_tid].view(1))\n",
    "            # Add in the emission scores \n",
    "            forward_var = (torch.cat(vvars) + feat).view(1,-1)\n",
    "            backpointers.append(bptrs)\n",
    "            \n",
    "        # Add transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag2idx[STOP_TAG]]\n",
    "        _, best_tid =  torch.max(terminal_var,1)\n",
    "        best_tid = best_tid.item()\n",
    "        path_score = terminal_var[0][best_tid]\n",
    "        \n",
    "        # Backtrace the backpointers to find the best path\n",
    "        best_path = [best_tid]\n",
    "        for bptrs in reversed(backpointers):\n",
    "            best_tid = bptrs[best_tid]\n",
    "            best_path.append(best_tid)\n",
    "        \n",
    "        # Remove the START_TAG \n",
    "        start = best_path.pop()\n",
    "        assert (start == self.tag2idx[START_TAG])\n",
    "        \n",
    "        # Reverse the path order\n",
    "        best_path.reverse()\n",
    "        \n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # Computes negative log likelihood of having tags given the sentence\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._viterbi_forward(feats)\n",
    "        score = self._score_sentence(feats, tags)\n",
    "        return forward_score - score\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        # Returns the best path score and the best path, given the setence\n",
    "        \n",
    "        # features from the BILSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "        \n",
    "        # Find the best path and its score, given the input sentence\n",
    "        best_score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return best_score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparams\n",
    "DIM_EMBEDDING = 500\n",
    "DIM_HIDDEN = 200\n",
    "LR = 0.0001\n",
    "N_EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:  [1045, 10620, 238, 824, 5, 3808, 229, 8246, 1]\n",
      "GT tag:  [0, 1, 2, 1, 1, 1, 2, 1, 1]\n",
      "==================================================\n",
      "Pretrain prediciton on sentence 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a8ad5e572e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pretrain prediciton on sentence 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecheck_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-fdee5c2139a6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# features from the BILSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mlstm_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lstm_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Find the best path and its score, given the input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-fdee5c2139a6>\u001b[0m in \u001b[0;36m_get_lstm_features\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \"\"\"\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Forward through LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         return F.embedding(\n\u001b[1;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = BILSTM_CRF(dim_embedding=DIM_EMBEDDING, \n",
    "                   dim_hidden=DIM_HIDDEN,\n",
    "                   vocab_size=len(word2idx),\n",
    "                   tag2idx=tag2idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Initial prediciton before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent, precheck_tag = prepare_sentence(train_data_bio[0], word2idx)\n",
    "    print(\"Sentence 0: \", precheck_sent)\n",
    "    print(\"GT tag: \", precheck_tag)\n",
    "    print(\"=\"*50)\n",
    "    print(\"Pretrain prediciton on sentence 0\")\n",
    "    print(model(precheck_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(N_EPOCH):\n",
    "    for _sent in train_data_bio:\n",
    "        \n",
    "        # Get input sentence and tags\n",
    "        sent, tags = prepare_sentence(_sent, word2idx)\n",
    "        \n",
    "        # Make sure no gradient lingering from previous iters\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        loss = model.neg_log_likelihood(sent, tags)\n",
    "        \n",
    "        # Update the weights\n",
    "        loss.backward()\n",
    "        optimizer.step()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predicitons after training\n",
    "with torch.no_grad():\n",
    "    sent0, tags0 = prepare_sentence(train_data_bio[0], word2idx)\n",
    "    print(\"Predicition after {N_EPOCH} epochs\")\n",
    "    print(\"GT: {tags0}\")\n",
    "    print(model(sent0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../trained/bilstm_crf_epoch:65_.sav']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "def get_current_time():\n",
    "    now = datetime.now()\n",
    "    now_str = f\"{now.strftime('%m')}_{now.strftime('%d')}_{now.strftime('%H')}_{now.strftime('%M')}\"\n",
    "    return now_str\n",
    "\n",
    "joblib.dump(model, '../progress_rnn2/bilstm_crf_epoch:65_.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
